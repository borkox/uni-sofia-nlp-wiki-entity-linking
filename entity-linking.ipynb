{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df84ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99033c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.1.tar.gz (84 kB)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Requirement already satisfied: tqdm in /home/bobi/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.11.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 554 kB/s eta 0:00:01    |███████                         | 4.5 MB 772 kB/s eta 0:00:22     |██████████████████▋             | 12.2 MB 574 kB/s eta 0:00:16     |██████████████████████          | 14.4 MB 587 kB/s eta 0:00:12\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/bobi/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.22.3)\n",
      "Requirement already satisfied: scikit-learn in /home/bobi/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: scipy in /home/bobi/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: nltk in /home/bobi/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (3.6.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 351 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.8.1\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 586 kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/bobi/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.1->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/bobi/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.1->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bobi/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.1->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /home/bobi/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.1->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bobi/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/bobi/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.8.1->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bobi/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.8.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 658 kB/s eta 0:00:01     |███████████████████             | 3.9 MB 555 kB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: click in /home/bobi/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/bobi/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.1-py3-none-any.whl size=125774 sha256=b165588051d24fd5d8aa962059764f6164d5d24abbc65b2a67c504ecfc5d9190\n",
      "  Stored in directory: /home/bobi/.cache/pip/wheels/59/69/f1/ac12a55f0e51bf7eef617044169e426d7affc8d0a27f7232e6\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers, torchvision, sentencepiece, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.8.1 sentence-transformers-2.2.1 sentencepiece-0.1.96 tokenizers-0.12.1 torchvision-0.12.0 transformers-4.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9dfef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "hugface_mdl = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8685c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len(mentions_df)=3915\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>left_context</th>\n",
       "      <th>link_title</th>\n",
       "      <th>link_text</th>\n",
       "      <th>right_context</th>\n",
       "      <th>url</th>\n",
       "      <th>mention_in_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>стил е съвременният международно признат</td>\n",
       "      <td>светски</td>\n",
       "      <td>NaN</td>\n",
       "      <td>календар на който се основава</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Григориански календар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>е съвременният международно признат светски</td>\n",
       "      <td>календар</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на който се основава и</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Григориански календар</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx                                 left_context link_title link_text  \\\n",
       "0   0     стил е съвременният международно признат    светски       NaN   \n",
       "1   1  е съвременният международно признат светски   календар       NaN   \n",
       "\n",
       "                   right_context  url        mention_in_page  \n",
       "0  календар на който се основава  NaN  Григориански календар  \n",
       "1         на който се основава и  NaN  Григориански календар  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_df = pd.read_csv('mentions.csv', dtype=str)\n",
    "print(f\"Len(mentions_df)={len(mentions_df)}\")\n",
    "mentions_df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02d29133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>left_context</th>\n",
       "      <th>link_title</th>\n",
       "      <th>link_text</th>\n",
       "      <th>right_context</th>\n",
       "      <th>url</th>\n",
       "      <th>mention_in_page</th>\n",
       "      <th>link_repr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>стил е съвременният международно признат</td>\n",
       "      <td>светски</td>\n",
       "      <td>NaN</td>\n",
       "      <td>календар на който се основава</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Григориански календар</td>\n",
       "      <td>светски</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>е съвременният международно признат светски</td>\n",
       "      <td>календар</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на който се основава и</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Григориански календар</td>\n",
       "      <td>календар</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx                                 left_context link_title link_text  \\\n",
       "0   0     стил е съвременният международно признат    светски       NaN   \n",
       "1   1  е съвременният международно признат светски   календар       NaN   \n",
       "\n",
       "                   right_context  url        mention_in_page link_repr  \n",
       "0  календар на който се основава  NaN  Григориански календар   светски  \n",
       "1         на който се основава и  NaN  Григориански календар  календар  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_df['link_repr'] = mentions_df.apply(lambda x: x['link_title'] if x['link_text']is None else x['link_title'], axis=1)\n",
    "mentions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4162fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len(entities_df)=201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Григориански календар</td>\n",
       "      <td>'Григорианският календар (понякога наричан и Г...</td>\n",
       "      <td>https://bg.wikipedia.org/wiki/%D0%93%D1%80%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GNU General Public License</td>\n",
       "      <td>GNU General Public License (на български преве...</td>\n",
       "      <td>https://bg.wikipedia.org/wiki/GNU_General_Publ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                       title  \\\n",
       "0    0       Григориански календар   \n",
       "1    1  GNU General Public License   \n",
       "\n",
       "                                                text  \\\n",
       "0  'Григорианският календар (понякога наричан и Г...   \n",
       "1  GNU General Public License (на български преве...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://bg.wikipedia.org/wiki/%D0%93%D1%80%D0%...  \n",
       "1  https://bg.wikipedia.org/wiki/GNU_General_Publ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df = pd.read_csv('entities.csv')\n",
    "print(f\"Len(entities_df)={len(entities_df)}\")\n",
    "entities_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3e131272",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible mentions:  220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx_mention</th>\n",
       "      <th>left_context</th>\n",
       "      <th>link_title</th>\n",
       "      <th>link_text</th>\n",
       "      <th>right_context</th>\n",
       "      <th>url_mention</th>\n",
       "      <th>mention_in_page</th>\n",
       "      <th>link_repr</th>\n",
       "      <th>idx_entitity</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url_entitity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>е въведен в употреба на</td>\n",
       "      <td>4 октомври</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1582 г в съответствие с</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Григориански календар</td>\n",
       "      <td>4 октомври</td>\n",
       "      <td>62</td>\n",
       "      <td>4 октомври</td>\n",
       "      <td>4 октомври е 277-ият ден в годината според гри...</td>\n",
       "      <td>https://bg.wikipedia.org/wiki/4_%D0%BE%D0%BA%D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205</td>\n",
       "      <td>са следните За събитията до</td>\n",
       "      <td>4 октомври</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1582 г включително има само</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Приемане на григорианския календар</td>\n",
       "      <td>4 октомври</td>\n",
       "      <td>62</td>\n",
       "      <td>4 октомври</td>\n",
       "      <td>4 октомври е 277-ият ден в годината според гри...</td>\n",
       "      <td>https://bg.wikipedia.org/wiki/4_%D0%BE%D0%BA%D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx_mention                 left_context  link_title link_text  \\\n",
       "0           6      е въведен в употреба на  4 октомври       NaN   \n",
       "1         205  са следните За събитията до  4 октомври       NaN   \n",
       "\n",
       "                 right_context url_mention  \\\n",
       "0      1582 г в съответствие с         NaN   \n",
       "1  1582 г включително има само         NaN   \n",
       "\n",
       "                      mention_in_page   link_repr  idx_entitity       title  \\\n",
       "0               Григориански календар  4 октомври            62  4 октомври   \n",
       "1  Приемане на григорианския календар  4 октомври            62  4 октомври   \n",
       "\n",
       "                                                text  \\\n",
       "0  4 октомври е 277-ият ден в годината според гри...   \n",
       "1  4 октомври е 277-ият ден в годината според гри...   \n",
       "\n",
       "                                        url_entitity  \n",
       "0  https://bg.wikipedia.org/wiki/4_%D0%BE%D0%BA%D...  \n",
       "1  https://bg.wikipedia.org/wiki/4_%D0%BE%D0%BA%D...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge mentions and entities (inner merge)\n",
    "merge_df = mentions_df.merge(entities_df, \\\n",
    "                           left_on='link_title', \\\n",
    "                           right_on='title', \\\n",
    "                           how='inner',\n",
    "                           suffixes=['_mention', '_entitity'])\n",
    "print('Eligible mentions: ', len(merge_df))\n",
    "merge_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d68efa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ba9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a65ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentionEntityDataset(Dataset):\n",
    "    def __init__(self, hugface_mdl, merge_df):\n",
    "        self.mention_vecs = hugface_mdl.encode(pd.array( \\\n",
    "            merge_df['left_context'] +' ' +\\\n",
    "            merge_df['link_repr'] + ' ' + \\\n",
    "            merge_df['right_context']))\n",
    "        self.entities_vec = hugface_mdl.encode(pd.array( \\\n",
    "            merge_df['title'] +' ' +\\\n",
    "            merge_df['text']))\n",
    "        \n",
    "        assert(len(self.mention_vecs) == len(self.entities_vec))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mention_vecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.mention_vecs[idx], self.entities_vec[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fce3fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MentionEntityDataset(hugface_mdl, merge_df)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c156f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentionToEntityNet(nn.Module):\n",
    "    def __init__(self, in_size=300, out_size=300):\n",
    "        super(MentionToEntityNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0494d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MentionToEntityNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=300, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MentionToEntityNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "300d2d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c4875e8a0e44898b7bdf450061f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30799/4149075451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization Finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30799/4149075451.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrans_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'token_type_ids'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "# Training cycle\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "DISPLAY_STEP = 2\n",
    "LEARNING_RATE = 0.01\n",
    "def train(model, dataset):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fct = torch.nn.CrossEntropyLoss() # Cross Entropy\n",
    "    model.train()\n",
    "    for epoch in range(1, MAX_EPOCHS+1):\n",
    "        losses = []\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, drop_last=False)\n",
    "        for x, y in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = loss_fct(logits, y)  \n",
    "            loss.backward()\n",
    "            loss_value = loss.item()\n",
    "            losses.append(loss_value)\n",
    "        \n",
    "        train_loss_value = np.mean(losses)\n",
    "        \n",
    "        # Display logs per each DISPLAY_STEP\n",
    "        if (epoch) % DISPLAY_STEP == 0:\n",
    "            print(\"Epoch: {:04d} loss={:.9f} \".format(epoch, train_loss_value))\n",
    "        \n",
    "    \n",
    "\n",
    "train(model, dataset)\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416b2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
